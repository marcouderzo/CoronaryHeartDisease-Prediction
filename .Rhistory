lda.fit <- lda(HeartDisease~., data=train)
lda.fit
lda.pred <- predict(lda.fit, test, type="response")
lda.res <- lda.pred$posterior
# if we want to minimize the false positives the best result is when t = 0.6
lda.pred.best <- as.factor(ifelse(lda.res[,2] > 0.6, 1, 0))
lda.conf.mat <- table(test$HeartDisease, lda.pred.best)
lda.conf.mat
# accuracy, precision, recall, f1 score
lda.metrics <- calculate.metrics(lda.conf.mat)
lda.metrics
# ROC
lda.auc <- model.plot.roc(lda.res[,2], test$HeartDisease)
lda.auc
ldahist(lda.pred$x[,1], g=lda.pred$class, col=2)
qda.fit <- qda(HeartDisease~., data=train)
qda.pred <- predict(qda.fit, test)
qda.pred.best <- as.factor(ifelse(lda.res[,2] > 0.5, 1, 0))
qda.conf.mat <- table(qda.pred.best, test$HeartDisease)
qda.conf.mat
qda.metrics <- calculate.metrics(qda.conf.mat)
qda.metrics
qda.auc <- model.plot.roc(qda.pred$posterior[,2], test$HeartDisease)
qda.auc
glm.model <- glm(data=train, HeartDisease~., family="binomial")
glm_summary <- summary(glm.model)
glm_summary
r2 <- 1 - (glm_summary$deviance/glm_summary$null.deviance)
1/(1-r2)
prediction.glm.model <- predict(glm.model, newdata=test, type="response")
prediction.glm.model.binary <- ifelse(prediction.glm.model > 0.6, 1, 0)
conf_matrix <- table(test$HeartDisease, prediction.glm.model.binary)
glm.model.metrics <- calculate.metrics(conf_matrix)
glm.model.metrics
glm.model.1 <- update(glm.model, ~. - Age)
glm.model.2 <- update(glm.model.1, ~. - RestingECG)
glm.model.3 <- update(glm.model.2, ~. - MaxHR)
glm.model.4 <- update(glm.model.3, ~. - RestingBP)
glm.models = list(glm.model, glm.model.1, glm.model.2, glm.model.3, glm.model.4)
for (mdl in glm.models){
r2 <- 1 - (mdl$deviance/mdl$null.deviance)
cat("R-Squared: ", r2, "\n")
vif <- 1/(1-r2)
cat("VIF: ", vif, "\n")
}
glm.models = list(glm.model, glm.model.1, glm.model.2, glm.model.3, glm.model.4)
for (mdl in glm.models){
glm.bic <- BIC(mdl)
print(glm.bic)
}
thresholds = c(0.3, 0.4, 0.5, 0.6)
for (thr in thresholds) {
prediction.glm.model.4 <- predict(glm.model.4, newdata=test, type="response")
prediction.glm.model.4.binary <- ifelse(prediction.glm.model > thr, 1, 0)
conf_matrix <- table(test$HeartDisease, prediction.glm.model.4.binary)
conf_matrix
glm.model.4.metrics <- calculate.metrics(conf_matrix)
cat("Threshold: ", thr, "\n")
cat("Accuracy, Precision, Rec, F1-Score", paste(glm.model.4.metrics, collapse = ", "), "\n")
}
# Now set best one.0.4
glm.model.4.roc <- model.plot.roc(prediction.glm.model.4, test$HeartDisease)
X <- model.matrix(glm.model)
y <- train$HeartDisease
lasso.model <- cv.glmnet(X, y, family = "binomial", type.measure = "class")
lasso.coef <- coef(lasso.model, s = "lambda.min")
lasso.vars <- rownames(lasso.coef)[-1][lasso.coef[-1,] != 0]
cat("Selected variables with Lasso Regression:\n\n", paste(lasso.vars, collapse = "\n"))
X_test <- model.matrix(glm.model, data = test)
y_pred <- predict(lasso.model, newx = X_test, s = "lambda.min", type = "response")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)  # Convert probabilities to classes
lasso.conf.mat <- table(y_pred_class, test$HeartDisease)
lasso.conf.mat
lasso.metrics <- calculate.metrics(lasso.conf.mat)
lasso.metrics
lasso.roc <- model.plot.roc(y_pred, test$HeartDisease)
X <- model.matrix(glm.model)
y <- train$HeartDisease
fit <- cv.glmnet(X, y, family = "binomial", alpha = 0, type.measure = "deviance")
coef(fit, s = "lambda.min")
y_pred <- predict(fit, newx = X_test, s = "lambda.min", type = "response")
y_pred_class <- ifelse(y_pred > 0.5, 1, 0)  # Convert probabilities to classes
ridge.conf.mat <- table(y_pred_class, test$HeartDisease)
ridge.conf.mat
ridge.metrics <- calculate.metrics(ridge.conf.mat)
ridge.metrics
ridge.roc <- model.plot.roc(y_pred, test$HeartDisease)
# Full model
glm.model.full <- glm(data=train, HeartDisease~., family="binomial")
deviance(glm.model.full)
pi.hat <- predict(glm.model.full, type="response")
DF <- -2*sum(train$HeartDisease*log(pi.hat)+(1-train$HeartDisease)*log(1-pi.hat))
df.F <- glm.model.full$df.residual
glm.model.reduced <- glm.model.4
deviance(glm.model.reduced)
pi.hat <- predict(glm.model.reduced, type="response")
DR <- -2*sum(train$HeartDisease*log(pi.hat)+(1-train$HeartDisease)*log(1-pi.hat))
df.R <- glm.model.reduced$df.residual
# Deviance difference test
dev.test <- DR-DF
df <- df.R- df.F
pvalue <- 1-pchisq(dev.test, df)
pvalue
# deviance difference using the anova() function
anova(glm.model.reduced, glm.model.full, test="Chisq")
train$HeartDisease <- as.factor(train$HeartDisease)
test$HeartDisease <- as.factor(test$HeartDisease)
naivebayes.model <- naive_bayes(HeartDisease~., data=train)
naivebayes.prediction <- predict(naivebayes.model, newx = test, type = "prob")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)  # Convert probabilities to classes
naivebayes.conf.mat <- table(y_pred_class, test$HeartDisease)
naivebayes.metrics <- calculate.metrics(naivebayes.conf.mat)
naivebayes.metrics
#model.plot.roc(naivebayes.prediction, test$HeartDisease)
# acc, prec, rec, f1.score
lda.acc <- lda.metrics[1][[1]]
lda.prec <- lda.metrics[2][[1]]
lda.rec <- lda.metrics[3][[1]]
lda.f1 <- lda.metrics[4][[1]]
lda.auc <- lda.auc[[1]]
qda.acc <- qda.metrics[1][[1]]
qda.prec <- qda.metrics[2][[1]]
qda.rec <- qda.metrics[3][[1]]
qda.f1 <- qda.metrics[4][[1]]
qda.auc <- qda.auc[[1]]
glm.acc <- glm.model.4.metrics[[1]][[1]]
glm.prec <- glm.model.4.metrics[2][[1]]
glm.rec <- glm.model.4.metrics[3][[1]]
glm.f1 <- glm.model.4.metrics[4][[1]]
glm.model.4.auc <- glm.model.4.roc[[1]]
lasso.acc <- lasso.metrics[1][[1]]
lasso.prec <- lasso.metrics[2][[1]]
lasso.rec <- lasso.metrics[3][[1]]
lasso.f1 <- lasso.metrics[4][[1]]
lasso.auc <- lasso.roc[[1]]
ridge.acc <- ridge.metrics[1][[1]]
ridge.prec <- ridge.metrics[2][[1]]
ridge.rec <- ridge.metrics[3][[1]]
ridge.f1 <- ridge.metrics[4][[1]]
ridge.auc <- ridge.roc[[1]]
naivebayes.acc <- naivebayes.metrics[1][[1]]
naivebayes.prec <- naivebayes.metrics[2][[1]]
naivebayes.rec <- naivebayes.metrics[3][[1]]
naivebayes.f1 <- naivebayes.metrics[4][[1]]
#naivebayes.auc <- naivebayes.roc[[1]]
acc <- c(lda.acc, qda.acc, glm.acc, lasso.acc, ridge.acc, naivebayes.acc)
prec <- c(lda.prec, qda.prec, glm.prec, lasso.prec, ridge.prec, naivebayes.prec)
rec <- c(lda.rec, qda.rec, glm.rec, lasso.rec, ridge.rec, naivebayes.rec)
f1.score <- c(lda.f1, qda.f1, glm.f1, lasso.f1, ridge.f1, naivebayes.f1)
auc <- c(lda.auc, qda.auc, glm.model.4.auc, lasso.auc, ridge.auc, 0) # naivebayes.auc to be fixed.
model_performance <- matrix(c(acc, prec, rec, f1.score, auc), nrow = 6, ncol = 5, byrow = TRUE)
model_names <- c("LDA", "QDA", "Logistic Regression", "Lasso Regression", "Ridge Regression", "Naive Bayes")
performance_summary <- data.frame(Model = model_names, model_performance)
colnames(performance_summary) <- c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "AUC")
print(performance_summary)
train$HeartDisease <- as.factor(train$HeartDisease)
test$HeartDisease <- as.factor(test$HeartDisease)
naivebayes.model <- naive_bayes(HeartDisease~., data=train)
naivebayes.prediction <- predict(naivebayes.model, newx = test, type = "prob")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)  # Convert probabilities to classes
naivebayes.conf.mat <- table(y_pred_class, test$HeartDisease)
naivebayes.metrics <- calculate.metrics(naivebayes.conf.mat)
naivebayes.metrics
model.plot.roc(naivebayes.prediction, test$HeartDisease)
naivebayes.prediction
lda.pred
dim(lda.pred)
size(lda.pred)
length(lda.pred)
dim(lda.pred)
ncol(lda.pred)
nrow(lda.pred)
naivebayes.prediction[:,1]
naivebayes.prediction[:;1]
naivebayes.prediction[:1]
naivebayes.prediction[1]
naivebayes.prediction[:][1]
naivebayes.prediction[,1]
train$HeartDisease <- as.factor(train$HeartDisease)
test$HeartDisease <- as.factor(test$HeartDisease)
naivebayes.model <- naive_bayes(HeartDisease~., data=train)
naivebayes.prediction <- predict(naivebayes.model, newx = test, type = "prob")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)  # Convert probabilities to classes
naivebayes.conf.mat <- table(y_pred_class, test$HeartDisease)
naivebayes.metrics <- calculate.metrics(naivebayes.conf.mat)
naivebayes.metrics
model.plot.roc(naivebayes.prediction[,1], test$HeartDisease)
train$HeartDisease <- as.factor(train$HeartDisease)
test$HeartDisease <- as.factor(test$HeartDisease)
naivebayes.model <- naive_bayes(HeartDisease~., data=train)
naivebayes.prediction <- predict(naivebayes.model, newx = test, type = "prob")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)  # Convert probabilities to classes
naivebayes.conf.mat <- table(y_pred_class, test$HeartDisease)
naivebayes.metrics <- calculate.metrics(naivebayes.conf.mat)
naivebayes.metrics
naivebayes.auc <- model.plot.roc(naivebayes.prediction[,1], test$HeartDisease[1:length(naivebayes.prediction[,1])])
train$HeartDisease <- as.factor(train$HeartDisease)
test$HeartDisease <- as.factor(test$HeartDisease)
naivebayes.model <- naive_bayes(HeartDisease~., data=test)
naivebayes.prediction <- predict(naivebayes.model, newx = test, type = "prob")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)  # Convert probabilities to classes
naivebayes.conf.mat <- table(y_pred_class, test$HeartDisease)
naivebayes.metrics <- calculate.metrics(naivebayes.conf.mat)
naivebayes.metrics
naivebayes.auc <- model.plot.roc(naivebayes.prediction[,2], test$HeartDisease)
[[1]]
train$HeartDisease <- as.factor(train$HeartDisease)
test$HeartDisease <- as.factor(test$HeartDisease)
naivebayes.model <- naive_bayes(HeartDisease~., data=test) # NB can't be trained, so use data=test
naivebayes.prediction <- predict(naivebayes.model, newx = test, type = "prob")
y_pred_class <- ifelse(y_pred > 0.4, 1, 0)
naivebayes.conf.mat <- table(y_pred_class, test$HeartDisease)
naivebayes.metrics <- calculate.metrics(naivebayes.conf.mat)
naivebayes.metrics
naivebayes.auc <- model.plot.roc(naivebayes.prediction[,2], test$HeartDisease)
train$HeartDisease <- as.factor(train$HeartDisease)
test$HeartDisease <- as.factor(test$HeartDisease)
naivebayes.model <- naive_bayes(HeartDisease~., data=test) # NB can't be trained, so use data=test
naivebayes.prediction <- predict(naivebayes.model, newx = test, type = "prob")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)
naivebayes.conf.mat <- table(y_pred_class, test$HeartDisease)
naivebayes.metrics <- calculate.metrics(naivebayes.conf.mat)
naivebayes.metrics
naivebayes.auc <- model.plot.roc(naivebayes.prediction[,2], test$HeartDisease)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(MASS)
library(pROC)
library(class)
library(ggplot2)
library(ggcorrplot)
library(gridExtra)
library(corrplot)
library(correlation)
library(ggm)
library(igraph)
library(tidymodels)
library(naivebayes)
library(ROCR)
library(glmnet)
library(stats)
data <- read.csv("data/heart_data.csv", stringsAsFactors = T)
attach(data)
prop.table(table(HeartDisease))
# continuous variables
cont.idx <- c(1,4,5,8,10)
colours <- c("#F8766D", "#00BFC4")
# Age
age.plot <- ggplot(data, aes(x=Age, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_density(alpha=0.4) +
ggtitle("Age - Density Plot") + xlab("Age") +
guides(fill = guide_legend(title="Heart disease"))
# RestingBP
restingBP.plot <- ggplot(data, aes(x=RestingBP, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_density(alpha=0.4) +
ggtitle("RestingBP - Density Plot") + xlab("RestingBP") +
guides(fill = guide_legend(title="Heart disease"))
# Cholesterol
chol.plot <- ggplot(data, aes(x=Cholesterol, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_density(alpha=0.4) +
ggtitle("Cholesterol - Density Plot") + xlab("Cholesterol") +
guides(fill = guide_legend(title="Heart disease"))
# MaxHR
maxHR.plot <- ggplot(data, aes(x=MaxHR, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_density(alpha=0.4) +
ggtitle("MaxHR - Density Plot") + xlab("MaxHR") +
guides(fill = guide_legend(title="Heart disease"))
# Oldpeak
oldpeak.plot <- ggplot(data, aes(x=Oldpeak, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_density(alpha=0.4) +
ggtitle("Oldpeak - Density Plot") + xlab("Oldpeak") +
guides(fill = guide_legend(title="Heart disease"))
# FastingBS
fastingBS.plot <- ggplot(data, aes(x=FastingBS, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_bar(alpha=0.5, position="dodge") +
guides(fill = guide_legend(title="Heart disease"))
chol.plot
oldpeak.plot
fastingBS.plot
age.box <- boxplot(Age ~ HeartDisease, col=colours)
maxHR.box <- boxplot(MaxHR ~ HeartDisease, col=colours)
# Sex
sex.plot <- ggplot(data, aes(x=Sex, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_bar(alpha=0.5, position="dodge") +
guides(fill = guide_legend(title="Heart disease"))
# ChestPainType
cpt.plot <- ggplot(data, aes(x=ChestPainType, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_bar(alpha=0.5, position="dodge") +
guides(fill = guide_legend(title="Heart disease"))
# RestingECG
restingECG.plot <- ggplot(data, aes(x=RestingECG, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_bar(alpha=0.5, position="dodge") +
guides(fill = guide_legend(title="Heart disease"))
# ExerciseAngina
exAn.plot <- ggplot(data, aes(x=ExerciseAngina, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_bar(alpha=0.5, position="dodge") +
guides(fill = guide_legend(title="Heart disease"))
# ST_Slope
st.plot <- ggplot(data, aes(x=ST_Slope, group=HeartDisease,
fill=factor(HeartDisease))) +
geom_bar(alpha=0.5, position="dodge") +
guides(fill = guide_legend(title="Heart disease"))
cpt.plot
restingECG.plot
exAn.plot
st.plot
head(data[Cholesterol == 0, c("RestingBP", "MaxHR", "RestingECG")])
cor.data <- cor(data[,cont.idx])
corrplot(cor.data,
method="color",
diag=F,
tl.cex=0.4,
number.cex=0.5,
tl.col="black",
addCoef.col="grey50",
cl.pos="n")
S <- var(data[,cont.idx])
R <- -cov2cor(solve(S))
G <- abs(R)>0.1
diag(G) <- 0
set.seed(123)
split <- initial_split(data[,-c(5)], prop=0.75)
train <- training(split)
test <- testing(split)
calculate.metrics <- function(conf.mat) {
acc <- sum(diag(conf.mat))/sum(conf.mat)
prec <- conf.mat[2,2] / sum(conf.mat[,2])
rec <- conf.mat[2,2] / sum(conf.mat[2,])
f1.score <- 2*prec*rec/(prec+rec)
out <- list(acc, prec, rec, f1.score)
return(out)
}
model.plot.roc <- function(predm, labl) {
pred <- prediction(predm, labl)
perf <- performance(pred, measure="tpr", x.measure="fpr")
plot(perf, main="ROC")
abline(a=0, b= 1)
auc.perf <- performance(pred, measure = "auc")
return(auc.perf@y.values)
}
lda.fit <- lda(HeartDisease~., data=train)
lda.fit
lda.pred <- predict(lda.fit, test, type="response")
lda.res <- lda.pred$posterior
# if we want to minimize the false positives the best result is when t = 0.6
lda.pred.best <- as.factor(ifelse(lda.res[,2] > 0.6, 1, 0))
lda.conf.mat <- table(test$HeartDisease, lda.pred.best)
lda.conf.mat
# accuracy, precision, recall, f1 score
lda.metrics <- calculate.metrics(lda.conf.mat)
lda.metrics
# ROC
lda.auc <- model.plot.roc(lda.res[,2], test$HeartDisease)
lda.auc
ldahist(lda.pred$x[,1], g=lda.pred$class, col=2)
qda.fit <- qda(HeartDisease~., data=train)
qda.pred <- predict(qda.fit, test)
qda.pred.best <- as.factor(ifelse(lda.res[,2] > 0.5, 1, 0))
qda.conf.mat <- table(qda.pred.best, test$HeartDisease)
qda.conf.mat
qda.metrics <- calculate.metrics(qda.conf.mat)
qda.metrics
qda.auc <- model.plot.roc(qda.pred$posterior[,2], test$HeartDisease)
qda.auc
glm.model <- glm(data=train, HeartDisease~., family="binomial")
glm_summary <- summary(glm.model)
glm_summary
r2 <- 1 - (glm_summary$deviance/glm_summary$null.deviance)
1/(1-r2)
prediction.glm.model <- predict(glm.model, newdata=test, type="response")
prediction.glm.model.binary <- ifelse(prediction.glm.model > 0.6, 1, 0)
conf_matrix <- table(test$HeartDisease, prediction.glm.model.binary)
glm.model.metrics <- calculate.metrics(conf_matrix)
glm.model.metrics
glm.model.1 <- update(glm.model, ~. - Age)
glm.model.2 <- update(glm.model.1, ~. - RestingECG)
glm.model.3 <- update(glm.model.2, ~. - MaxHR)
glm.model.4 <- update(glm.model.3, ~. - RestingBP)
glm.models = list(glm.model, glm.model.1, glm.model.2, glm.model.3, glm.model.4)
for (mdl in glm.models){
r2 <- 1 - (mdl$deviance/mdl$null.deviance)
cat("R-Squared: ", r2, "\n")
vif <- 1/(1-r2)
cat("VIF: ", vif, "\n")
}
glm.models = list(glm.model, glm.model.1, glm.model.2, glm.model.3, glm.model.4)
for (mdl in glm.models){
glm.bic <- BIC(mdl)
print(glm.bic)
}
thresholds = c(0.3, 0.4, 0.5, 0.6)
for (thr in thresholds) {
prediction.glm.model.4 <- predict(glm.model.4, newdata=test, type="response")
prediction.glm.model.4.binary <- ifelse(prediction.glm.model > thr, 1, 0)
conf_matrix <- table(test$HeartDisease, prediction.glm.model.4.binary)
conf_matrix
glm.model.4.metrics <- calculate.metrics(conf_matrix)
cat("Threshold: ", thr, "\n")
cat("Accuracy, Precision, Rec, F1-Score", paste(glm.model.4.metrics, collapse = ", "), "\n")
}
# Now set best one
cat("\n \n", "Best Threshold: 0.4")
prediction.glm.model.4 <- predict(glm.model.4, newdata=test, type="response")
prediction.glm.model.4.binary <- ifelse(prediction.glm.model > 0.4, 1, 0)
conf_matrix <- table(test$HeartDisease, prediction.glm.model.4.binary)
conf_matrix
glm.model.4.metrics <- calculate.metrics(conf_matrix)
cat("Accuracy, Precision, Rec, F1-Score", paste(glm.model.4.metrics, collapse = ", "), "\n")
glm.model.4.roc <- model.plot.roc(prediction.glm.model.4, test$HeartDisease)
X <- model.matrix(glm.model)
y <- train$HeartDisease
lasso.model <- cv.glmnet(X, y, family = "binomial", type.measure = "class")
lasso.coef <- coef(lasso.model, s = "lambda.min")
lasso.vars <- rownames(lasso.coef)[-1][lasso.coef[-1,] != 0]
cat("Selected variables with Lasso Regression:\n\n", paste(lasso.vars, collapse = "\n"))
X_test <- model.matrix(glm.model, data = test)
y_pred <- predict(lasso.model, newx = X_test, s = "lambda.min", type = "response")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)  # Convert probabilities to classes
lasso.conf.mat <- table(y_pred_class, test$HeartDisease)
lasso.conf.mat
lasso.metrics <- calculate.metrics(lasso.conf.mat)
lasso.metrics
lasso.roc <- model.plot.roc(y_pred, test$HeartDisease)
X <- model.matrix(glm.model)
y <- train$HeartDisease
fit <- cv.glmnet(X, y, family = "binomial", alpha = 0, type.measure = "deviance")
coef(fit, s = "lambda.min")
y_pred <- predict(fit, newx = X_test, s = "lambda.min", type = "response")
y_pred_class <- ifelse(y_pred > 0.5, 1, 0)  # Convert probabilities to classes
ridge.conf.mat <- table(y_pred_class, test$HeartDisease)
ridge.conf.mat
ridge.metrics <- calculate.metrics(ridge.conf.mat)
ridge.metrics
ridge.roc <- model.plot.roc(y_pred, test$HeartDisease)
# Full model
glm.model.full <- glm(data=train, HeartDisease~., family="binomial")
deviance(glm.model.full)
pi.hat <- predict(glm.model.full, type="response")
DF <- -2*sum(train$HeartDisease*log(pi.hat)+(1-train$HeartDisease)*log(1-pi.hat))
df.F <- glm.model.full$df.residual
glm.model.reduced <- glm.model.4
deviance(glm.model.reduced)
pi.hat <- predict(glm.model.reduced, type="response")
DR <- -2*sum(train$HeartDisease*log(pi.hat)+(1-train$HeartDisease)*log(1-pi.hat))
df.R <- glm.model.reduced$df.residual
# Deviance difference test
dev.test <- DR-DF
df <- df.R- df.F
pvalue <- 1-pchisq(dev.test, df)
pvalue
# deviance difference using the anova() function
anova(glm.model.reduced, glm.model.full, test="Chisq")
train$HeartDisease <- as.factor(train$HeartDisease)
test$HeartDisease <- as.factor(test$HeartDisease)
naivebayes.model <- naive_bayes(HeartDisease~., data=test) # NB can't be trained, so use data=test
naivebayes.prediction <- predict(naivebayes.model, newx = test, type = "prob")
y_pred_class <- ifelse(y_pred > 0.6, 1, 0)
naivebayes.conf.mat <- table(y_pred_class, test$HeartDisease)
naivebayes.metrics <- calculate.metrics(naivebayes.conf.mat)
naivebayes.metrics
naivebayes.roc <- model.plot.roc(naivebayes.prediction[,2], test$HeartDisease)
# acc, prec, rec, f1.score
lda.acc <- lda.metrics[1][[1]]
lda.prec <- lda.metrics[2][[1]]
lda.rec <- lda.metrics[3][[1]]
lda.f1 <- lda.metrics[4][[1]]
lda.auc <- lda.auc[[1]]
qda.acc <- qda.metrics[1][[1]]
qda.prec <- qda.metrics[2][[1]]
qda.rec <- qda.metrics[3][[1]]
qda.f1 <- qda.metrics[4][[1]]
qda.auc <- qda.auc[[1]]
glm.acc <- glm.model.4.metrics[[1]][[1]]
glm.prec <- glm.model.4.metrics[2][[1]]
glm.rec <- glm.model.4.metrics[3][[1]]
glm.f1 <- glm.model.4.metrics[4][[1]]
glm.model.4.auc <- glm.model.4.roc[[1]]
lasso.acc <- lasso.metrics[1][[1]]
lasso.prec <- lasso.metrics[2][[1]]
lasso.rec <- lasso.metrics[3][[1]]
lasso.f1 <- lasso.metrics[4][[1]]
lasso.auc <- lasso.roc[[1]]
ridge.acc <- ridge.metrics[1][[1]]
ridge.prec <- ridge.metrics[2][[1]]
ridge.rec <- ridge.metrics[3][[1]]
ridge.f1 <- ridge.metrics[4][[1]]
ridge.auc <- ridge.roc[[1]]
naivebayes.acc <- naivebayes.metrics[1][[1]]
naivebayes.prec <- naivebayes.metrics[2][[1]]
naivebayes.rec <- naivebayes.metrics[3][[1]]
naivebayes.f1 <- naivebayes.metrics[4][[1]]
naivebayes.auc <- naivebayes.roc[[1]]
acc <- c(lda.acc, qda.acc, glm.acc, lasso.acc, ridge.acc, naivebayes.acc)
prec <- c(lda.prec, qda.prec, glm.prec, lasso.prec, ridge.prec, naivebayes.prec)
rec <- c(lda.rec, qda.rec, glm.rec, lasso.rec, ridge.rec, naivebayes.rec)
f1.score <- c(lda.f1, qda.f1, glm.f1, lasso.f1, ridge.f1, naivebayes.f1)
auc <- c(lda.auc, qda.auc, glm.model.4.auc, lasso.auc, ridge.auc, naivebayes.auc)
model_performance <- matrix(c(acc, prec, rec, f1.score, auc), nrow = 6, ncol = 5, byrow = TRUE)
model_names <- c("LDA", "QDA", "Logistic Regression", "Lasso Regression", "Ridge Regression", "Naive Bayes")
performance_summary <- data.frame(Model = model_names, model_performance)
colnames(performance_summary) <- c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "AUC")
print(performance_summary)
